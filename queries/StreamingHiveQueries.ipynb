{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac65936f-ebe4-43ac-9fdc-f050e1aa9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9b54890-8209-4083-a1ae-dfe5efa0caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HiveQueries\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a85f068-1141-4cd8-afa0-6dd91b204ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|paymentMethod|      total_sales|\n",
      "+-------------+-----------------+\n",
      "|   Debit Card|57267.98000000002|\n",
      "|       PayPal|         45508.37|\n",
      "|  Credit Card|         44203.07|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Total Sales Amount by Payment Method\n",
    "total_sales_amount_by_payment_method = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            paymentMethod, \n",
    "            SUM(totalAmount) AS total_sales\n",
    "        FROM \n",
    "            kafka\n",
    "        WHERE \n",
    "            eventType = 'purchase'\n",
    "        GROUP BY \n",
    "            paymentMethod\n",
    "        ORDER BY \n",
    "            total_sales DESC;\n",
    "    \"\"\")\n",
    "# Show the results\n",
    "total_sales_amount_by_payment_method.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0ab0a8-4014-4d1d-a1f1-8e771f63090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|      category|total_events|\n",
      "+--------------+------------+\n",
      "|          null|        1846|\n",
      "|Home & Kitchen|         197|\n",
      "|         Books|         173|\n",
      "|   Electronics|         160|\n",
      "|      Clothing|         128|\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Most Popular Categories by Number of Events\n",
    "most_popular_category = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            category, \n",
    "            COUNT(*) AS total_events\n",
    "        FROM \n",
    "            kafka\n",
    "        GROUP BY \n",
    "            category\n",
    "        ORDER BY \n",
    "            total_events DESC;\n",
    "    \"\"\")\n",
    "# Show the results\n",
    "most_popular_category.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d79e0171-6c0e-4e87-9b00-b744427fead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|customerId|total_revenue|\n",
      "+----------+-------------+\n",
      "|     40568|        798.8|\n",
      "|     24184|        499.3|\n",
      "|     36839|       497.62|\n",
      "|     32730|       497.26|\n",
      "|     66714|       496.19|\n",
      "|     65429|        494.8|\n",
      "|     41784|        493.9|\n",
      "|     38514|       493.74|\n",
      "|     32457|       491.46|\n",
      "|     45241|       491.37|\n",
      "|     29717|       490.85|\n",
      "|     58979|       490.55|\n",
      "|     58051|       490.06|\n",
      "|     79665|       489.21|\n",
      "|     11613|       488.36|\n",
      "|     19200|       488.21|\n",
      "|     40107|       486.33|\n",
      "|     26946|       486.06|\n",
      "|     89694|       485.79|\n",
      "|     24218|       485.29|\n",
      "+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Revenue by Customer\n",
    "revenue_by_customer = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            customerId, \n",
    "            SUM(totalAmount) AS total_revenue\n",
    "        FROM \n",
    "            kafka\n",
    "        WHERE \n",
    "            eventType = 'purchase'\n",
    "        GROUP BY \n",
    "            customerId\n",
    "        ORDER BY \n",
    "            total_revenue DESC;\n",
    "\n",
    "    \"\"\")\n",
    "# Show the results\n",
    "revenue_by_customer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d4edb01-3a4f-4371-aea0-046802a7916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|event_hour|       total_sales|\n",
      "+----------+------------------+\n",
      "|         3|            2350.4|\n",
      "|         4|            2468.7|\n",
      "|        11|11588.650000000001|\n",
      "|        12|           4466.29|\n",
      "|        13|           1436.93|\n",
      "|        15|          16607.09|\n",
      "|        16|          76627.44|\n",
      "|        17|           2817.18|\n",
      "|        18|          10504.49|\n",
      "|        19|15367.099999999999|\n",
      "|        20|           2745.15|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hourly Sales Analysis\n",
    "hourly_sales_analysis = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            event_hour, \n",
    "            SUM(totalAmount) AS total_sales\n",
    "        FROM \n",
    "            kafka\n",
    "        WHERE \n",
    "            eventType = 'purchase'\n",
    "        GROUP BY \n",
    "            event_hour\n",
    "        ORDER BY \n",
    "            event_hour;\n",
    "\n",
    "    \"\"\")\n",
    "# Show the results\n",
    "hourly_sales_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d721a64-fb5d-42fe-b8a1-e553ea96454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
